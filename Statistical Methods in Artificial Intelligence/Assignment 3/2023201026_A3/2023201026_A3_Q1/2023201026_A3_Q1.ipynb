{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NZpidSCxhE9f",
        "sBGtTbiZmIKk"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "QbzgaJqqkXkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "NZpidSCxhE9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "2LmiTghOS0Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGSH-osNTDOp",
        "outputId": "d30fc6dc-404a-4a39-f556-d79463d1020f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 76778223.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "Zu5196c6TGQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()"
      ],
      "metadata": {
        "id": "Hkb1S627TJ8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "18ZFeAXFTOxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-3-lg_bTR5T",
        "outputId": "cc63f228-7ece-42ac-c936-70025d8ad8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.016\n",
            "[1,   200] loss: 0.013\n",
            "[1,   300] loss: 0.015\n",
            "[1,   400] loss: 0.016\n",
            "[1,   500] loss: 0.016\n",
            "[1,   600] loss: 0.017\n",
            "[1,   700] loss: 0.017\n",
            "[2,   100] loss: 0.016\n",
            "[2,   200] loss: 0.015\n",
            "[2,   300] loss: 0.014\n",
            "[2,   400] loss: 0.014\n",
            "[2,   500] loss: 0.016\n",
            "[2,   600] loss: 0.015\n",
            "[2,   700] loss: 0.016\n",
            "[3,   100] loss: 0.013\n",
            "[3,   200] loss: 0.015\n",
            "[3,   300] loss: 0.016\n",
            "[3,   400] loss: 0.017\n",
            "[3,   500] loss: 0.017\n",
            "[3,   600] loss: 0.017\n",
            "[3,   700] loss: 0.016\n",
            "[4,   100] loss: 0.014\n",
            "[4,   200] loss: 0.014\n",
            "[4,   300] loss: 0.015\n",
            "[4,   400] loss: 0.016\n",
            "[4,   500] loss: 0.014\n",
            "[4,   600] loss: 0.016\n",
            "[4,   700] loss: 0.015\n",
            "[5,   100] loss: 0.013\n",
            "[5,   200] loss: 0.013\n",
            "[5,   300] loss: 0.012\n",
            "[5,   400] loss: 0.015\n",
            "[5,   500] loss: 0.015\n",
            "[5,   600] loss: 0.017\n",
            "[5,   700] loss: 0.017\n",
            "[6,   100] loss: 0.012\n",
            "[6,   200] loss: 0.012\n",
            "[6,   300] loss: 0.013\n",
            "[6,   400] loss: 0.013\n",
            "[6,   500] loss: 0.016\n",
            "[6,   600] loss: 0.015\n",
            "[6,   700] loss: 0.014\n",
            "[7,   100] loss: 0.016\n",
            "[7,   200] loss: 0.016\n",
            "[7,   300] loss: 0.013\n",
            "[7,   400] loss: 0.012\n",
            "[7,   500] loss: 0.013\n",
            "[7,   600] loss: 0.013\n",
            "[7,   700] loss: 0.015\n",
            "[8,   100] loss: 0.013\n",
            "[8,   200] loss: 0.014\n",
            "[8,   300] loss: 0.015\n",
            "[8,   400] loss: 0.014\n",
            "[8,   500] loss: 0.015\n",
            "[8,   600] loss: 0.014\n",
            "[8,   700] loss: 0.013\n",
            "[9,   100] loss: 0.013\n",
            "[9,   200] loss: 0.012\n",
            "[9,   300] loss: 0.011\n",
            "[9,   400] loss: 0.014\n",
            "[9,   500] loss: 0.013\n",
            "[9,   600] loss: 0.015\n",
            "[9,   700] loss: 0.013\n",
            "[10,   100] loss: 0.013\n",
            "[10,   200] loss: 0.013\n",
            "[10,   300] loss: 0.012\n",
            "[10,   400] loss: 0.014\n",
            "[10,   500] loss: 0.013\n",
            "[10,   600] loss: 0.013\n",
            "[10,   700] loss: 0.014\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "total_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "average_loss = total_loss / len(test_loader)"
      ],
      "metadata": {
        "id": "fF-SRH_zTVRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')\n",
        "print(f'Average loss on the test set: {average_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjX-agjMVX33",
        "outputId": "02afa34f-916f-43e1-bb5f-d3621b47ab2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 52.16%\n",
            "Average loss on the test set: 3.6983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Increasing number of epochs**"
      ],
      "metadata": {
        "id": "btKly9OIWWme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(15):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xok-H7nDVfWt",
        "outputId": "15d8a2fd-082a-400d-8773-7c5853f9d5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.012\n",
            "[1,   200] loss: 0.011\n",
            "[1,   300] loss: 0.012\n",
            "[1,   400] loss: 0.014\n",
            "[1,   500] loss: 0.013\n",
            "[1,   600] loss: 0.015\n",
            "[1,   700] loss: 0.014\n",
            "[2,   100] loss: 0.012\n",
            "[2,   200] loss: 0.012\n",
            "[2,   300] loss: 0.013\n",
            "[2,   400] loss: 0.013\n",
            "[2,   500] loss: 0.013\n",
            "[2,   600] loss: 0.014\n",
            "[2,   700] loss: 0.013\n",
            "[3,   100] loss: 0.011\n",
            "[3,   200] loss: 0.012\n",
            "[3,   300] loss: 0.011\n",
            "[3,   400] loss: 0.012\n",
            "[3,   500] loss: 0.013\n",
            "[3,   600] loss: 0.013\n",
            "[3,   700] loss: 0.013\n",
            "[4,   100] loss: 0.010\n",
            "[4,   200] loss: 0.010\n",
            "[4,   300] loss: 0.013\n",
            "[4,   400] loss: 0.013\n",
            "[4,   500] loss: 0.014\n",
            "[4,   600] loss: 0.014\n",
            "[4,   700] loss: 0.013\n",
            "[5,   100] loss: 0.011\n",
            "[5,   200] loss: 0.010\n",
            "[5,   300] loss: 0.011\n",
            "[5,   400] loss: 0.011\n",
            "[5,   500] loss: 0.011\n",
            "[5,   600] loss: 0.013\n",
            "[5,   700] loss: 0.012\n",
            "[6,   100] loss: 0.011\n",
            "[6,   200] loss: 0.011\n",
            "[6,   300] loss: 0.012\n",
            "[6,   400] loss: 0.012\n",
            "[6,   500] loss: 0.012\n",
            "[6,   600] loss: 0.013\n",
            "[6,   700] loss: 0.013\n",
            "[7,   100] loss: 0.010\n",
            "[7,   200] loss: 0.010\n",
            "[7,   300] loss: 0.011\n",
            "[7,   400] loss: 0.010\n",
            "[7,   500] loss: 0.012\n",
            "[7,   600] loss: 0.012\n",
            "[7,   700] loss: 0.014\n",
            "[8,   100] loss: 0.011\n",
            "[8,   200] loss: 0.011\n",
            "[8,   300] loss: 0.011\n",
            "[8,   400] loss: 0.014\n",
            "[8,   500] loss: 0.013\n",
            "[8,   600] loss: 0.012\n",
            "[8,   700] loss: 0.012\n",
            "[9,   100] loss: 0.011\n",
            "[9,   200] loss: 0.010\n",
            "[9,   300] loss: 0.011\n",
            "[9,   400] loss: 0.012\n",
            "[9,   500] loss: 0.011\n",
            "[9,   600] loss: 0.011\n",
            "[9,   700] loss: 0.010\n",
            "[10,   100] loss: 0.011\n",
            "[10,   200] loss: 0.010\n",
            "[10,   300] loss: 0.010\n",
            "[10,   400] loss: 0.011\n",
            "[10,   500] loss: 0.011\n",
            "[10,   600] loss: 0.012\n",
            "[10,   700] loss: 0.012\n",
            "[11,   100] loss: 0.012\n",
            "[11,   200] loss: 0.011\n",
            "[11,   300] loss: 0.012\n",
            "[11,   400] loss: 0.011\n",
            "[11,   500] loss: 0.011\n",
            "[11,   600] loss: 0.011\n",
            "[11,   700] loss: 0.011\n",
            "[12,   100] loss: 0.010\n",
            "[12,   200] loss: 0.009\n",
            "[12,   300] loss: 0.011\n",
            "[12,   400] loss: 0.012\n",
            "[12,   500] loss: 0.012\n",
            "[12,   600] loss: 0.013\n",
            "[12,   700] loss: 0.012\n",
            "[13,   100] loss: 0.009\n",
            "[13,   200] loss: 0.010\n",
            "[13,   300] loss: 0.011\n",
            "[13,   400] loss: 0.010\n",
            "[13,   500] loss: 0.010\n",
            "[13,   600] loss: 0.011\n",
            "[13,   700] loss: 0.012\n",
            "[14,   100] loss: 0.010\n",
            "[14,   200] loss: 0.012\n",
            "[14,   300] loss: 0.011\n",
            "[14,   400] loss: 0.012\n",
            "[14,   500] loss: 0.012\n",
            "[14,   600] loss: 0.011\n",
            "[14,   700] loss: 0.012\n",
            "[15,   100] loss: 0.012\n",
            "[15,   200] loss: 0.010\n",
            "[15,   300] loss: 0.009\n",
            "[15,   400] loss: 0.010\n",
            "[15,   500] loss: 0.011\n",
            "[15,   600] loss: 0.011\n",
            "[15,   700] loss: 0.013\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "total_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "average_loss = total_loss / len(test_loader)\n",
        "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')\n",
        "print(f'Average loss on the test set: {average_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2AmP0LwW8zE",
        "outputId": "925c5066-e1c8-476d-bbc3-c04d1ff11207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 52.31%\n",
            "Average loss on the test set: 4.4260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying different parameters**"
      ],
      "metadata": {
        "id": "DSbASw8MgK65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VariedMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VariedMLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(3072, 2048),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "model = VariedMLP()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "e69EBtx3aT2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWKZZjhhgbEz",
        "outputId": "788f240f-7061-4ba7-8465-2fa935aaff30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 2.0584\n",
            "Epoch 1, Batch 200, Loss: 1.7826\n",
            "Epoch 1, Batch 300, Loss: 1.6973\n",
            "Epoch 1, Batch 400, Loss: 1.6711\n",
            "Epoch 1, Batch 500, Loss: 1.6004\n",
            "Epoch 1, Batch 600, Loss: 1.6158\n",
            "Epoch 1, Batch 700, Loss: 1.5400\n",
            "Epoch 2, Batch 100, Loss: 1.5181\n",
            "Epoch 2, Batch 200, Loss: 1.4636\n",
            "Epoch 2, Batch 300, Loss: 1.4773\n",
            "Epoch 2, Batch 400, Loss: 1.4537\n",
            "Epoch 2, Batch 500, Loss: 1.4752\n",
            "Epoch 2, Batch 600, Loss: 1.4313\n",
            "Epoch 2, Batch 700, Loss: 1.4555\n",
            "Epoch 3, Batch 100, Loss: 1.3802\n",
            "Epoch 3, Batch 200, Loss: 1.3715\n",
            "Epoch 3, Batch 300, Loss: 1.3545\n",
            "Epoch 3, Batch 400, Loss: 1.3522\n",
            "Epoch 3, Batch 500, Loss: 1.3727\n",
            "Epoch 3, Batch 600, Loss: 1.3651\n",
            "Epoch 3, Batch 700, Loss: 1.3363\n",
            "Epoch 4, Batch 100, Loss: 1.2670\n",
            "Epoch 4, Batch 200, Loss: 1.2735\n",
            "Epoch 4, Batch 300, Loss: 1.2957\n",
            "Epoch 4, Batch 400, Loss: 1.2762\n",
            "Epoch 4, Batch 500, Loss: 1.2844\n",
            "Epoch 4, Batch 600, Loss: 1.2847\n",
            "Epoch 4, Batch 700, Loss: 1.2736\n",
            "Epoch 5, Batch 100, Loss: 1.1956\n",
            "Epoch 5, Batch 200, Loss: 1.1910\n",
            "Epoch 5, Batch 300, Loss: 1.2100\n",
            "Epoch 5, Batch 400, Loss: 1.2134\n",
            "Epoch 5, Batch 500, Loss: 1.1980\n",
            "Epoch 5, Batch 600, Loss: 1.2195\n",
            "Epoch 5, Batch 700, Loss: 1.2060\n",
            "Epoch 6, Batch 100, Loss: 1.1410\n",
            "Epoch 6, Batch 200, Loss: 1.1285\n",
            "Epoch 6, Batch 300, Loss: 1.1555\n",
            "Epoch 6, Batch 400, Loss: 1.1467\n",
            "Epoch 6, Batch 500, Loss: 1.1541\n",
            "Epoch 6, Batch 600, Loss: 1.1594\n",
            "Epoch 6, Batch 700, Loss: 1.1523\n",
            "Epoch 7, Batch 100, Loss: 1.0557\n",
            "Epoch 7, Batch 200, Loss: 1.0715\n",
            "Epoch 7, Batch 300, Loss: 1.0973\n",
            "Epoch 7, Batch 400, Loss: 1.1024\n",
            "Epoch 7, Batch 500, Loss: 1.0855\n",
            "Epoch 7, Batch 600, Loss: 1.0863\n",
            "Epoch 7, Batch 700, Loss: 1.1067\n",
            "Epoch 8, Batch 100, Loss: 1.0169\n",
            "Epoch 8, Batch 200, Loss: 0.9930\n",
            "Epoch 8, Batch 300, Loss: 1.0424\n",
            "Epoch 8, Batch 400, Loss: 1.0506\n",
            "Epoch 8, Batch 500, Loss: 1.0270\n",
            "Epoch 8, Batch 600, Loss: 1.0665\n",
            "Epoch 8, Batch 700, Loss: 1.0445\n",
            "Epoch 9, Batch 100, Loss: 0.9603\n",
            "Epoch 9, Batch 200, Loss: 0.9476\n",
            "Epoch 9, Batch 300, Loss: 0.9763\n",
            "Epoch 9, Batch 400, Loss: 0.9903\n",
            "Epoch 9, Batch 500, Loss: 0.9759\n",
            "Epoch 9, Batch 600, Loss: 0.9823\n",
            "Epoch 9, Batch 700, Loss: 1.0340\n",
            "Epoch 10, Batch 100, Loss: 0.8937\n",
            "Epoch 10, Batch 200, Loss: 0.9020\n",
            "Epoch 10, Batch 300, Loss: 0.9320\n",
            "Epoch 10, Batch 400, Loss: 0.9281\n",
            "Epoch 10, Batch 500, Loss: 0.9256\n",
            "Epoch 10, Batch 600, Loss: 0.9713\n",
            "Epoch 10, Batch 700, Loss: 0.9402\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "total_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "average_loss = total_loss / len(test_loader)\n",
        "\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy:.2f}%')\n",
        "print(f'Average loss on the test set: {average_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMBr-438gXG2",
        "outputId": "c4914dc7-095d-4278-989b-0d5750637b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 55.45%\n",
            "Average loss on the test set: 1.3045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**"
      ],
      "metadata": {
        "id": "jpqzCMXYk6X6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 1:**\n",
        "\n",
        "**Performance (10 epochs):** Achieved 52.16% accuracy with an average loss of 3.6983 on the test set.\n",
        "\n",
        "**Performance (15 epochs):** Slight improvement in accuracy to 52.31% but with an increased average loss of 4.4260, suggesting potential overfitting or that the model has reached its performance capacity on the dataset.\n",
        "\n",
        "**Model 2:**\n",
        "\n",
        "**Performance (10 epochs):** This model shows a notable improvement, reaching 55.45% accuracy with a significantly lower average loss of 1.3045 on the test set.\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "The introduction of dropout and a wider network in Model 2 helped in reducing overfitting and improved model generalization, as evidenced by both higher accuracy and lower loss.\n",
        "\n",
        "Switching from ReLU to LeakyReLU and from Adam to SGD with momentum also seemed to positively impact the model's ability to learn from the CIFAR-10 dataset.\n",
        "These results highlight the significance of architectural choices, activation functions, and optimizers in designing neural networks, especially for complex tasks like image classification."
      ],
      "metadata": {
        "id": "nYrgE2CdlPiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "sBGtTbiZmIKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "3TcqNaH6mG2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "N-VpgNz-nClq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.4f}')\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMrmX49RnMz6",
        "outputId": "f0c13030-d50a-440d-9d73-cee65499be03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 1.8995\n",
            "Epoch 1, Batch 200, Loss: 1.5324\n",
            "Epoch 1, Batch 300, Loss: 1.3983\n",
            "Epoch 1, Batch 400, Loss: 1.3119\n",
            "Epoch 1, Batch 500, Loss: 1.2333\n",
            "Epoch 1, Batch 600, Loss: 1.2014\n",
            "Epoch 1, Batch 700, Loss: 1.1278\n",
            "Epoch 2, Batch 100, Loss: 0.9941\n",
            "Epoch 2, Batch 200, Loss: 0.9534\n",
            "Epoch 2, Batch 300, Loss: 0.9209\n",
            "Epoch 2, Batch 400, Loss: 0.8972\n",
            "Epoch 2, Batch 500, Loss: 0.8957\n",
            "Epoch 2, Batch 600, Loss: 0.8583\n",
            "Epoch 2, Batch 700, Loss: 0.8379\n",
            "Epoch 3, Batch 100, Loss: 0.7267\n",
            "Epoch 3, Batch 200, Loss: 0.7316\n",
            "Epoch 3, Batch 300, Loss: 0.7089\n",
            "Epoch 3, Batch 400, Loss: 0.7078\n",
            "Epoch 3, Batch 500, Loss: 0.7004\n",
            "Epoch 3, Batch 600, Loss: 0.6888\n",
            "Epoch 3, Batch 700, Loss: 0.7061\n",
            "Epoch 4, Batch 100, Loss: 0.5640\n",
            "Epoch 4, Batch 200, Loss: 0.5895\n",
            "Epoch 4, Batch 300, Loss: 0.5784\n",
            "Epoch 4, Batch 400, Loss: 0.5726\n",
            "Epoch 4, Batch 500, Loss: 0.5865\n",
            "Epoch 4, Batch 600, Loss: 0.5638\n",
            "Epoch 4, Batch 700, Loss: 0.5478\n",
            "Epoch 5, Batch 100, Loss: 0.4353\n",
            "Epoch 5, Batch 200, Loss: 0.4285\n",
            "Epoch 5, Batch 300, Loss: 0.4485\n",
            "Epoch 5, Batch 400, Loss: 0.4558\n",
            "Epoch 5, Batch 500, Loss: 0.4555\n",
            "Epoch 5, Batch 600, Loss: 0.4671\n",
            "Epoch 5, Batch 700, Loss: 0.4698\n",
            "Epoch 6, Batch 100, Loss: 0.3073\n",
            "Epoch 6, Batch 200, Loss: 0.3226\n",
            "Epoch 6, Batch 300, Loss: 0.3291\n",
            "Epoch 6, Batch 400, Loss: 0.3458\n",
            "Epoch 6, Batch 500, Loss: 0.3680\n",
            "Epoch 6, Batch 600, Loss: 0.3591\n",
            "Epoch 6, Batch 700, Loss: 0.3745\n",
            "Epoch 7, Batch 100, Loss: 0.2192\n",
            "Epoch 7, Batch 200, Loss: 0.2109\n",
            "Epoch 7, Batch 300, Loss: 0.2366\n",
            "Epoch 7, Batch 400, Loss: 0.2473\n",
            "Epoch 7, Batch 500, Loss: 0.2640\n",
            "Epoch 7, Batch 600, Loss: 0.2733\n",
            "Epoch 7, Batch 700, Loss: 0.2605\n",
            "Epoch 8, Batch 100, Loss: 0.1549\n",
            "Epoch 8, Batch 200, Loss: 0.1396\n",
            "Epoch 8, Batch 300, Loss: 0.1506\n",
            "Epoch 8, Batch 400, Loss: 0.1808\n",
            "Epoch 8, Batch 500, Loss: 0.2160\n",
            "Epoch 8, Batch 600, Loss: 0.2066\n",
            "Epoch 8, Batch 700, Loss: 0.1933\n",
            "Epoch 9, Batch 100, Loss: 0.0933\n",
            "Epoch 9, Batch 200, Loss: 0.0958\n",
            "Epoch 9, Batch 300, Loss: 0.1090\n",
            "Epoch 9, Batch 400, Loss: 0.1500\n",
            "Epoch 9, Batch 500, Loss: 0.1452\n",
            "Epoch 9, Batch 600, Loss: 0.1616\n",
            "Epoch 9, Batch 700, Loss: 0.1505\n",
            "Epoch 10, Batch 100, Loss: 0.0780\n",
            "Epoch 10, Batch 200, Loss: 0.0849\n",
            "Epoch 10, Batch 300, Loss: 0.0887\n",
            "Epoch 10, Batch 400, Loss: 0.1107\n",
            "Epoch 10, Batch 500, Loss: 0.1194\n",
            "Epoch 10, Batch 600, Loss: 0.1160\n",
            "Epoch 10, Batch 700, Loss: 0.1372\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "total_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "average_loss = total_loss / len(test_loader)\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy:.2f}%')\n",
        "print(f'Average loss on the test set: {average_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRQsaRq3nTs9",
        "outputId": "80ad7094-7359-4a90-8d25-8d21f6bb8012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 75.08%\n",
            "Average loss on the test set: 1.1649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying different parameters**"
      ],
      "metadata": {
        "id": "Iy9KfoZznfC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UpdatedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UpdatedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(256 * 2 * 2, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "        self.elu = nn.ELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.elu(self.conv1(x)))\n",
        "        x = self.pool(self.elu(self.conv2(x)))\n",
        "        x = self.pool(self.elu(self.conv3(x)))\n",
        "        x = self.pool(self.elu(self.conv4(x)))\n",
        "        x = x.view(-1, 256 * 2 * 2)\n",
        "        x = self.elu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LgAvr5cWniNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UpdatedCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlpm2cbIoTBe",
        "outputId": "4acb8ee8-4677-44ca-b7d5-1a5a4390f241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 2.2043\n",
            "Epoch 1, Batch 200, Loss: 1.9058\n",
            "Epoch 1, Batch 300, Loss: 1.6636\n",
            "Epoch 1, Batch 400, Loss: 1.5319\n",
            "Epoch 1, Batch 500, Loss: 1.4456\n",
            "Epoch 1, Batch 600, Loss: 1.3909\n",
            "Epoch 1, Batch 700, Loss: 1.3313\n",
            "Epoch 2, Batch 100, Loss: 1.1946\n",
            "Epoch 2, Batch 200, Loss: 1.1452\n",
            "Epoch 2, Batch 300, Loss: 1.1211\n",
            "Epoch 2, Batch 400, Loss: 1.0704\n",
            "Epoch 2, Batch 500, Loss: 1.0342\n",
            "Epoch 2, Batch 600, Loss: 1.0111\n",
            "Epoch 2, Batch 700, Loss: 0.9799\n",
            "Epoch 3, Batch 100, Loss: 0.8553\n",
            "Epoch 3, Batch 200, Loss: 0.8424\n",
            "Epoch 3, Batch 300, Loss: 0.8438\n",
            "Epoch 3, Batch 400, Loss: 0.8589\n",
            "Epoch 3, Batch 500, Loss: 0.8188\n",
            "Epoch 3, Batch 600, Loss: 0.8625\n",
            "Epoch 3, Batch 700, Loss: 0.8189\n",
            "Epoch 4, Batch 100, Loss: 0.6596\n",
            "Epoch 4, Batch 200, Loss: 0.6795\n",
            "Epoch 4, Batch 300, Loss: 0.7023\n",
            "Epoch 4, Batch 400, Loss: 0.6774\n",
            "Epoch 4, Batch 500, Loss: 0.6647\n",
            "Epoch 4, Batch 600, Loss: 0.6734\n",
            "Epoch 4, Batch 700, Loss: 0.6558\n",
            "Epoch 5, Batch 100, Loss: 0.5179\n",
            "Epoch 5, Batch 200, Loss: 0.5272\n",
            "Epoch 5, Batch 300, Loss: 0.5399\n",
            "Epoch 5, Batch 400, Loss: 0.5663\n",
            "Epoch 5, Batch 500, Loss: 0.5495\n",
            "Epoch 5, Batch 600, Loss: 0.5689\n",
            "Epoch 5, Batch 700, Loss: 0.5703\n",
            "Epoch 6, Batch 100, Loss: 0.3669\n",
            "Epoch 6, Batch 200, Loss: 0.3959\n",
            "Epoch 6, Batch 300, Loss: 0.4231\n",
            "Epoch 6, Batch 400, Loss: 0.4276\n",
            "Epoch 6, Batch 500, Loss: 0.4664\n",
            "Epoch 6, Batch 600, Loss: 0.4630\n",
            "Epoch 6, Batch 700, Loss: 0.4496\n",
            "Epoch 7, Batch 100, Loss: 0.2911\n",
            "Epoch 7, Batch 200, Loss: 0.2806\n",
            "Epoch 7, Batch 300, Loss: 0.2916\n",
            "Epoch 7, Batch 400, Loss: 0.3545\n",
            "Epoch 7, Batch 500, Loss: 0.3461\n",
            "Epoch 7, Batch 600, Loss: 0.3848\n",
            "Epoch 7, Batch 700, Loss: 0.3775\n",
            "Epoch 8, Batch 100, Loss: 0.2121\n",
            "Epoch 8, Batch 200, Loss: 0.2262\n",
            "Epoch 8, Batch 300, Loss: 0.2364\n",
            "Epoch 8, Batch 400, Loss: 0.2610\n",
            "Epoch 8, Batch 500, Loss: 0.2929\n",
            "Epoch 8, Batch 600, Loss: 0.2790\n",
            "Epoch 8, Batch 700, Loss: 0.3128\n",
            "Epoch 9, Batch 100, Loss: 0.1715\n",
            "Epoch 9, Batch 200, Loss: 0.1488\n",
            "Epoch 9, Batch 300, Loss: 0.1622\n",
            "Epoch 9, Batch 400, Loss: 0.1852\n",
            "Epoch 9, Batch 500, Loss: 0.2023\n",
            "Epoch 9, Batch 600, Loss: 0.2289\n",
            "Epoch 9, Batch 700, Loss: 0.2349\n",
            "Epoch 10, Batch 100, Loss: 0.1180\n",
            "Epoch 10, Batch 200, Loss: 0.1243\n",
            "Epoch 10, Batch 300, Loss: 0.1255\n",
            "Epoch 10, Batch 400, Loss: 0.1483\n",
            "Epoch 10, Batch 500, Loss: 0.1773\n",
            "Epoch 10, Batch 600, Loss: 0.1774\n",
            "Epoch 10, Batch 700, Loss: 0.2026\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "total_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "average_loss = total_loss / len(test_loader)\n",
        "\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy:.2f}%')\n",
        "print(f'Average loss on the test set: {average_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21bjRYjGonRn",
        "outputId": "49783fb5-edaf-4992-df5a-0b212484f5b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 74.23%\n",
            "Average loss on the test set: 1.1496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**\n",
        "\n",
        "**Model 1:**\n",
        "\n",
        "Performance: Achieved an accuracy of 75.08% on the test set with an average loss of 1.1649.\n",
        "\n",
        "**Model 2:**\n",
        "\n",
        "Performance: Reached an accuracy of 74.23% on the test set with a slightly lower average loss of 1.1496.\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "Model 2's increased complexity did not lead to higher accuracy compared to Model 1, suggesting that CIFAR-10 may not benefit from the added complexity or that further tuning is needed to leverage the model's full potential.\n",
        "\n",
        "Model 2 achieved a slightly lower average loss, indicating it might make more confident predictions than Model 1, despite not achieving higher accuracy.\n",
        "\n",
        "Using ELU in Model 2 did not provide a clear performance advantage"
      ],
      "metadata": {
        "id": "nm39SKgn8xXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG"
      ],
      "metadata": {
        "id": "cWzsEh709vyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. GPU will be used for training.\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Training will default to CPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc-ZFwPv9yMM",
        "outputId": "c41639fb-cd0f-42ad-9dfd-47a66907f521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. GPU will be used for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "2TzuViOO_9mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_features = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_features, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2havytcYAC-Q",
        "outputId": "c5a7ec79-0cc9-45c4-cdc4-cf982e7e65f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 85.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbhI1RJiAH3S",
        "outputId": "98847e94-b48a-4208-969b-872b0d7a8a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 63296285.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Pg9c_FbKAxJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW0Fcj-SA57u",
        "outputId": "58acd73d-fa66-4848-9f7f-2f9ea579e8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss / 100:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uClMegSmBEwZ",
        "outputId": "35c598ef-fe52-44a7-98c2-c9adf38cdc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 0.9353\n",
            "Epoch 1, Batch 200, Loss: 0.7295\n",
            "Epoch 1, Batch 300, Loss: 0.6632\n",
            "Epoch 1, Batch 400, Loss: 0.6559\n",
            "Epoch 1, Batch 500, Loss: 0.7099\n",
            "Epoch 1, Batch 600, Loss: 0.6595\n",
            "Epoch 1, Batch 700, Loss: 0.6725\n",
            "Epoch 2, Batch 100, Loss: 0.4828\n",
            "Epoch 2, Batch 200, Loss: 0.4972\n",
            "Epoch 2, Batch 300, Loss: 0.5199\n",
            "Epoch 2, Batch 400, Loss: 0.5702\n",
            "Epoch 2, Batch 500, Loss: 0.5291\n",
            "Epoch 2, Batch 600, Loss: 0.5521\n",
            "Epoch 2, Batch 700, Loss: 0.5264\n",
            "Epoch 3, Batch 100, Loss: 0.4295\n",
            "Epoch 3, Batch 200, Loss: 0.4136\n",
            "Epoch 3, Batch 300, Loss: 0.4298\n",
            "Epoch 3, Batch 400, Loss: 0.4237\n",
            "Epoch 3, Batch 500, Loss: 0.4343\n",
            "Epoch 3, Batch 600, Loss: 0.4393\n",
            "Epoch 3, Batch 700, Loss: 0.4918\n",
            "Epoch 4, Batch 100, Loss: 0.3033\n",
            "Epoch 4, Batch 200, Loss: 0.3772\n",
            "Epoch 4, Batch 300, Loss: 0.4080\n",
            "Epoch 4, Batch 400, Loss: 0.3804\n",
            "Epoch 4, Batch 500, Loss: 0.3923\n",
            "Epoch 4, Batch 600, Loss: 0.4364\n",
            "Epoch 4, Batch 700, Loss: 0.3975\n",
            "Epoch 5, Batch 100, Loss: 0.2899\n",
            "Epoch 5, Batch 200, Loss: 0.3568\n",
            "Epoch 5, Batch 300, Loss: 0.3149\n",
            "Epoch 5, Batch 400, Loss: 0.3494\n",
            "Epoch 5, Batch 500, Loss: 0.3331\n",
            "Epoch 5, Batch 600, Loss: 0.3554\n",
            "Epoch 5, Batch 700, Loss: 0.3928\n",
            "Epoch 6, Batch 100, Loss: 0.2989\n",
            "Epoch 6, Batch 200, Loss: 0.3460\n",
            "Epoch 6, Batch 300, Loss: 0.3285\n",
            "Epoch 6, Batch 400, Loss: 0.3267\n",
            "Epoch 6, Batch 500, Loss: 0.3478\n",
            "Epoch 6, Batch 600, Loss: 0.3273\n",
            "Epoch 6, Batch 700, Loss: 0.3325\n",
            "Epoch 7, Batch 100, Loss: 0.3134\n",
            "Epoch 7, Batch 200, Loss: 0.2827\n",
            "Epoch 7, Batch 300, Loss: 0.3149\n",
            "Epoch 7, Batch 400, Loss: 0.3359\n",
            "Epoch 7, Batch 500, Loss: 0.2933\n",
            "Epoch 7, Batch 600, Loss: 0.3069\n",
            "Epoch 7, Batch 700, Loss: 0.3207\n",
            "Epoch 8, Batch 100, Loss: 0.2807\n",
            "Epoch 8, Batch 200, Loss: 0.2655\n",
            "Epoch 8, Batch 300, Loss: 0.2782\n",
            "Epoch 8, Batch 400, Loss: 0.2751\n",
            "Epoch 8, Batch 500, Loss: 0.2483\n",
            "Epoch 8, Batch 600, Loss: 0.2744\n",
            "Epoch 8, Batch 700, Loss: 0.2745\n",
            "Epoch 9, Batch 100, Loss: 0.2795\n",
            "Epoch 9, Batch 200, Loss: 0.2660\n",
            "Epoch 9, Batch 300, Loss: 0.3196\n",
            "Epoch 9, Batch 400, Loss: 0.2718\n",
            "Epoch 9, Batch 500, Loss: 0.2600\n",
            "Epoch 9, Batch 600, Loss: 0.3259\n",
            "Epoch 9, Batch 700, Loss: 0.2753\n",
            "Epoch 10, Batch 100, Loss: 0.2085\n",
            "Epoch 10, Batch 200, Loss: 0.2232\n",
            "Epoch 10, Batch 300, Loss: 0.2215\n",
            "Epoch 10, Batch 400, Loss: 0.2631\n",
            "Epoch 10, Batch 500, Loss: 0.2754\n",
            "Epoch 10, Batch 600, Loss: 0.2488\n",
            "Epoch 10, Batch 700, Loss: 0.2459\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "total_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "average_loss = total_loss / len(test_loader)\n",
        "\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy:.2f}%')\n",
        "print(f'Average loss on the test set: {average_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLpaTlCkBg6k",
        "outputId": "59b3500d-685d-4d5a-8e49-a138fe329c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 87.51%\n",
            "Average loss on the test set: 0.5710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions"
      ],
      "metadata": {
        "id": "TSkQ8U_jP75L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy**\n",
        "\n",
        "MLP (VariedMLP): Achieved 55.45% accuracy with an average loss of 1.3045.\n",
        "\n",
        "CNN (SimpleCNN): Achieved 75.08% accuracy with an average loss of 1.1649.\n",
        "\n",
        "VGG-based Transfer Learning: Achieved 87.51% accuracy with an average loss of 0.5710.\n",
        "\n",
        "**Analysis**\n",
        "\n",
        "The MLP model, despite its simplicity and adjustments for a higher capacity lagged in performance. This is due to MLPs treating input images as flat arrays, thus ignoring the spatial hierarchy and structure within images that are important for effective feature extraction.\n",
        "\n",
        "The CNN model significantly outperformed the MLP model by leveraging convolutional layers. CNNs maintain the spatial relationships between pixels by applying filters that detect patterns and features\n",
        "\n",
        "The VGG-based model, utilizing transfer learning, showed the highest accuracy. This improvement can be attributed to the VGG model's extensive training on ImageNet, a much larger and diverse dataset.\n",
        "\n",
        "The VGG model, pre-trained on ImageNet and fine-tuned for CIFAR-10, not only achieved higher accuracy but also a significantly lower loss. This indicates better generalization and confidence in predictions compared to models trained from scratch."
      ],
      "metadata": {
        "id": "NpdeFuoTmQii"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BaNpetrAEDGy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}